# Jak DziaÅ‚a RAG System - Kompletne WyjaÅ›nienie

## ğŸ¯ PrzeglÄ…d Systemu

TwÃ³j RAG (Retrieval-Augmented Generation) system to zaawansowany pipeline, ktÃ³ry:
1. **Przetwarza dokumenty** (PDF, obrazy, tekst)
2. **Przechowuje je** w bazie wektorowej
3. **Wyszukuje relevantne fragmenty** na podstawie zapytaÅ„ uÅ¼ytkownika
4. **Generuje odpowiedzi** uÅ¼ywajÄ…c LLM z kontekstem

## ğŸ“Š Architektura - GÅ‚Ã³wne Komponenty

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UÅ»YTKOWNIK                                â”‚
â”‚              (wysyÅ‚a dokument lub zapytanie)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API ENDPOINTS                              â”‚
â”‚  â€¢ POST /documents/upload  - upload dokumentu                â”‚
â”‚  â€¢ POST /query            - zapytanie do systemu             â”‚
â”‚  â€¢ GET  /health           - status systemu                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
        â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DOCUMENT SERVICE â”‚    â”‚  QUERY SERVICE   â”‚
â”‚  (przetwarzanie) â”‚    â”‚   (wyszukiwanie) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ PARSERS â”‚            â”‚RETRIEVALâ”‚
    â”‚         â”‚            â”‚ ENGINE  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      VECTOR DATABASE (ChromaDB)      â”‚
â”‚   â€¢ Text embeddings                  â”‚
â”‚   â€¢ Visual embeddings                â”‚
â”‚   â€¢ Metadata                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Flow 1: Przetwarzanie Dokumentu

### Krok po kroku:

```
1. UPLOAD DOKUMENTU
   â†“
   User wysyÅ‚a PDF â†’ POST /documents/upload
   
2. PARSING
   â†“
   RAGAnythingParser:
   â€¢ Wykrywa typ dokumentu
   â€¢ Ekstraktuje tekst (pypdf lub MinerU)
   â€¢ Wykrywa obrazy i tabele
   â€¢ Zachowuje strukturÄ™ (headings, paragraphs)
   
3. CHUNKING (Semantic Chunking)
   â†“
   SemanticChunker:
   â€¢ Dzieli dokument na semantyczne fragmenty
   â€¢ Respektuje granice (paragrafy, sekcje)
   â€¢ Opcjonalnie: sentence-window (maÅ‚e chunki + kontekst)
   â€¢ Dodaje metadata (pozycja, typ, struktura)
   
4. EMBEDDING
   â†“
   OpenAI Embedder:
   â€¢ Generuje embeddingi dla kaÅ¼dego chunka
   â€¢ Model: text-embedding-3-small
   â€¢ Wymiar: 1536
   
5. INDEXING
   â†“
   RÃ³wnolegle:
   
   A) Vector Store (ChromaDB):
      â€¢ Zapisuje embeddingi
      â€¢ Przechowuje metadata
      â€¢ UmoÅ¼liwia semantic search
   
   B) BM25 Index:
      â€¢ Tokenizuje tekst
      â€¢ Buduje inverted index
      â€¢ UmoÅ¼liwia keyword search
      â€¢ Zapisuje na dysk (persistence)
   
6. POTWIERDZENIE
   â†“
   Zwraca document_id i status
```

### PrzykÅ‚ad:

```python
# User uploaduje dokument
POST /documents/upload
Content-Type: multipart/form-data
file: research_paper.pdf

# System przetwarza:
{
  "document_id": "doc_abc123",
  "filename": "research_paper.pdf",
  "status": "completed",
  "chunks_created": 45,
  "processing_time": 3.2
}
```

## ğŸ” Flow 2: Zapytanie (Query) - Enhanced Retrieval

To jest najwaÅ¼niejsza czÄ™Å›Ä‡! Tutaj dzieje siÄ™ magia z wszystkimi enhancements:

### Krok po kroku:

```
1. ZAPYTANIE UÅ»YTKOWNIKA
   â†“
   User: "What are the main findings about climate change?"
   
2. QUERY EXPANSION (opcjonalne, domyÅ›lnie wÅ‚Ä…czone)
   â†“
   QueryExpander generuje warianty zapytania:
   
   Metoda: Multi-Query (domyÅ›lna)
   â€¢ Original: "What are the main findings about climate change?"
   â€¢ Variant 1: "What are the key discoveries regarding climate change?"
   â€¢ Variant 2: "What are the primary results about global warming?"
   
   LUB Metoda: HyDE
   â€¢ Generuje hipotetyczny dokument odpowiadajÄ…cy na pytanie
   â€¢ UÅ¼ywa tego jako query
   
   Cache: Zapisuje wyniki (TTL: 1h)
   
3. HYBRID SEARCH (dla kaÅ¼dego wariantu)
   â†“
   RÃ³wnolegle wykonuje:
   
   A) VECTOR SEARCH (semantic)
      ChromaDB:
      â€¢ Embedding zapytania
      â€¢ Cosine similarity
      â€¢ Top-20 najbardziej podobnych chunkÃ³w
      â€¢ Wynik: [(chunk1, score1), (chunk2, score2), ...]
   
   B) KEYWORD SEARCH (lexical)
      BM25 Index:
      â€¢ Tokenizacja zapytania
      â€¢ BM25 scoring (k1=1.5, b=0.75)
      â€¢ Top-20 najlepiej matchujÄ…cych chunkÃ³w
      â€¢ Wynik: [(chunk3, score3), (chunk4, score4), ...]
   
4. RECIPROCAL RANK FUSION (RRF)
   â†“
   ÅÄ…czy wyniki z obu metod:
   
   Formula: RRF_score = Î£ 1/(k + rank_i)
   gdzie k=60 (staÅ‚a)
   
   Weights:
   â€¢ Vector: 0.7 (domyÅ›lnie)
   â€¢ Keyword: 0.3 (domyÅ›lnie)
   
   Wynik: Top-20 chunkÃ³w z najlepszymi combined scores
   
5. RERANKING (Cross-Encoder)
   â†“
   CrossEncoderReranker:
   â€¢ Model: ms-marco-MiniLM-L-6-v2
   â€¢ Dla kaÅ¼dej pary (query, chunk):
     - Oblicza precyzyjny relevance score
     - UÅ¼ywa attention mechanism
   â€¢ Batch processing (32 pary na raz)
   â€¢ GPU acceleration (jeÅ›li dostÄ™pne)
   â€¢ Score normalization [0, 1]
   
   Cache: Zapisuje scores dla par (query, chunk)
   
   Wynik: Top-5 najbardziej relevantnych chunkÃ³w
   
6. DEDUPLICATION (jeÅ›li query expansion)
   â†“
   JeÅ›li uÅ¼ywano wielu wariantÃ³w zapytania:
   â€¢ Merge wynikÃ³w z wszystkich wariantÃ³w
   â€¢ UsuÅ„ duplikaty (ten sam chunk_id)
   â€¢ Zachowaj najwyÅ¼szy score
   
7. CONTEXT PREPARATION
   â†“
   Dla top-5 chunkÃ³w:
   â€¢ Pobierz peÅ‚ny tekst
   â€¢ Pobierz metadata (source, page, position)
   â€¢ Formatuj jako kontekst dla LLM
   
8. LLM GENERATION
   â†“
   OpenAI GPT-4o-mini:
   â€¢ Prompt: "Based on the following context, answer: {query}"
   â€¢ Context: {top 5 chunks}
   â€¢ Temperature: 0.7
   â€¢ Max tokens: 500
   
9. RESPONSE
   â†“
   Zwraca:
   {
     "answer": "The main findings...",
     "sources": [
       {
         "chunk_id": "chunk_1",
         "document_id": "doc_abc123",
         "text": "...",
         "score": 0.95,
         "page": 3
       },
       ...
     ],
     "metadata": {
       "retrieval_method": "hybrid_reranked",
       "query_expansion": "multi-query",
       "num_candidates": 20,
       "reranking_time": 0.15,
       "total_time": 1.2
     }
   }
```

## ğŸ›ï¸ Konfiguracja - Co MoÅ¼esz KontrolowaÄ‡

### Environment Variables (.env):

```bash
# === LLM Settings ===
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# === Chunking ===
CHUNK_SIZE=512                    # Rozmiar chunka w tokenach
CHUNK_OVERLAP=50                  # Overlap miÄ™dzy chunkami
CHUNKING_STRATEGY=semantic        # fixed, semantic, sentence-window

# === Reranking ===
ENABLE_RERANKING=true            # WÅ‚Ä…cz/wyÅ‚Ä…cz reranking
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANKING_TOP_K=20               # Ile kandydatÃ³w do rerankingu
FINAL_TOP_K=5                    # Ile wynikÃ³w koÅ„cowych
ENABLE_GPU=true                  # GPU dla rerankingu

# === Hybrid Search ===
ENABLE_HYBRID_SEARCH=true        # WÅ‚Ä…cz/wyÅ‚Ä…cz hybrid search
VECTOR_WEIGHT=0.7                # Waga vector search (0-1)
KEYWORD_WEIGHT=0.3               # Waga keyword search (0-1)
BM25_K1=1.5                      # BM25 term frequency saturation
BM25_B=0.75                      # BM25 length normalization

# === Query Expansion ===
ENABLE_QUERY_EXPANSION=true      # WÅ‚Ä…cz/wyÅ‚Ä…cz expansion
EXPANSION_METHOD=multi-query     # hyde, multi-query, none
NUM_QUERY_VARIATIONS=3           # Ile wariantÃ³w generowaÄ‡
EXPANSION_CACHE_TTL=3600         # Cache TTL w sekundach

# === Performance ===
RERANKING_BATCH_SIZE=32          # Batch size dla rerankingu
CACHE_RERANKING_SCORES=true      # Cache scores
```

## ğŸ”¬ PrzykÅ‚ad DziaÅ‚ania - Krok po Kroku

### Scenariusz: User pyta o "machine learning algorithms"

```
1. Query Expansion:
   Original: "machine learning algorithms"
   Variant 1: "ML algorithm types"
   Variant 2: "supervised and unsupervised learning methods"

2. Hybrid Search (dla kaÅ¼dego wariantu):
   
   Vector Search (semantic):
   â€¢ "neural networks and deep learning" - score: 0.85
   â€¢ "classification and regression models" - score: 0.82
   â€¢ "training data and model optimization" - score: 0.78
   
   Keyword Search (BM25):
   â€¢ "machine learning algorithms include..." - score: 12.5
   â€¢ "algorithm selection for ML tasks..." - score: 11.2
   â€¢ "popular algorithms: SVM, Random Forest..." - score: 10.8

3. RRF Fusion:
   Combined scores (0.7 * vector + 0.3 * keyword):
   â€¢ Chunk A: 0.89 (high semantic + keyword match)
   â€¢ Chunk B: 0.85 (high semantic)
   â€¢ Chunk C: 0.81 (good keyword match)
   ... (top 20)

4. Reranking:
   Cross-encoder scores (query-chunk pairs):
   â€¢ Chunk A: 0.95 â­ (najbardziej relevant)
   â€¢ Chunk D: 0.92 â­
   â€¢ Chunk B: 0.88 â­
   â€¢ Chunk E: 0.85 â­
   â€¢ Chunk C: 0.82 â­

5. Final Result:
   Top 5 chunkÃ³w â†’ LLM â†’ Answer
```

## ğŸ¯ Dlaczego To DziaÅ‚a Lepiej?

### 1. **Query Expansion** - Rozumie intencjÄ™
- User moÅ¼e pytaÄ‡ rÃ³Å¼nie o to samo
- System generuje warianty i znajduje wiÄ™cej relevant content
- PrzykÅ‚ad: "ML" = "machine learning" = "artificial intelligence algorithms"

### 2. **Hybrid Search** - ÅÄ…czy semantic + keyword
- **Vector search**: rozumie znaczenie, kontekst, synonimy
- **Keyword search**: znajduje exact matches, terminy techniczne
- **Razem**: najlepsze z obu Å›wiatÃ³w

### 3. **Reranking** - Precyzyjne scorowanie
- Pierwszy pass (hybrid): szybki, znajduje kandydatÃ³w
- Drugi pass (reranking): dokÅ‚adny, wybiera najlepsze
- Cross-encoder: patrzy na caÅ‚Ä… parÄ™ (query, chunk) jednoczeÅ›nie

### 4. **Semantic Chunking** - Zachowuje kontekst
- Nie tnie w Å›rodku zdania
- Respektuje strukturÄ™ dokumentu
- Chunki majÄ… sens semantyczny

## ğŸ“Š Metryki i Monitoring

System loguje wszystko:

```python
# PrzykÅ‚adowe logi:
INFO: Query received: "machine learning algorithms"
INFO: Query expansion: generated 3 variations
INFO: Vector search: found 20 candidates in 0.05s
INFO: Keyword search: found 18 candidates in 0.02s
INFO: RRF fusion: merged to 25 unique chunks
INFO: Reranking: scored 25 pairs in 0.15s (GPU)
INFO: Final results: 5 chunks, avg score: 0.89
INFO: LLM generation: 1.2s
INFO: Total query time: 1.5s
```

Debug mode (dodaj `?debug=true`):
```json
{
  "metadata": {
    "timings": {
      "query_expansion": 0.08,
      "vector_search": 0.05,
      "keyword_search": 0.02,
      "rrf_fusion": 0.01,
      "reranking": 0.15,
      "llm_generation": 1.2
    },
    "scores": {
      "vector_contribution": 0.65,
      "keyword_contribution": 0.35,
      "reranking_improvement": 0.12
    },
    "candidates": {
      "initial": 25,
      "after_reranking": 5
    }
  }
}
```

## ğŸ”§ Troubleshooting

### Problem: Wyniki nie sÄ… relevantne
**RozwiÄ…zanie:**
1. ZwiÄ™ksz `RERANKING_TOP_K` (wiÄ™cej kandydatÃ³w)
2. ZmieÅ„ `EXPANSION_METHOD` na `hyde`
3. Dostosuj `VECTOR_WEIGHT` / `KEYWORD_WEIGHT`

### Problem: Zbyt wolne
**RozwiÄ…zanie:**
1. WyÅ‚Ä…cz query expansion: `ENABLE_QUERY_EXPANSION=false`
2. Zmniejsz `RERANKING_TOP_K`
3. WÅ‚Ä…cz GPU: `ENABLE_GPU=true`
4. ZwiÄ™ksz `RERANKING_BATCH_SIZE`

### Problem: Nie znajduje exact matches
**RozwiÄ…zanie:**
1. ZwiÄ™ksz `KEYWORD_WEIGHT` (np. 0.5)
2. SprawdÅº BM25 index: `GET /health`

## ğŸ“ Podsumowanie

TwÃ³j RAG system to **4-stage pipeline**:

1. **Document Processing** â†’ Parsing + Chunking + Embedding + Indexing
2. **Query Enhancement** â†’ Expansion + Hybrid Search + RRF Fusion
3. **Reranking** â†’ Cross-encoder scoring
4. **Generation** â†’ LLM z kontekstem

**Kluczowe zalety:**
- âœ… Znajduje wiÄ™cej relevant content (query expansion)
- âœ… ÅÄ…czy semantic + keyword search (hybrid)
- âœ… Precyzyjne scorowanie (reranking)
- âœ… Zachowuje kontekst (semantic chunking)
- âœ… Szybkie i skalowalne (caching, GPU)
- âœ… Monitorowalne (detailed metrics)

**To jest state-of-the-art RAG system!** ğŸš€
